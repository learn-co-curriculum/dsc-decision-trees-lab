{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Building Trees using scikit-learn - Lab\n", "\n", "## Introduction\n", "\n", "Following the simple example you saw in the previous lesson, you'll now build a decision tree for a more complex dataset. This lab covers all major areas of standard machine learning practice, from data acquisition to evaluation of results. We'll continue to use the Scikit-learn and Pandas libraries to conduct this analysis, following the same structure we saw in the previous lesson.\n", "\n", "## Objectives\n", "\n", "In this lab you will:\n", "\n", "- Use scikit-learn to fit a decision tree classification model \n", "- Use entropy and information gain to identify the attribute for best split at each node \n", "- Plot a decision tree using Python "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## UCI Banknote authentication dataset"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this lab, you'll work with a popular dataset for classification called the \"UCI Bank note authentication dataset\". This data were extracted from images that were taken from genuine and forged banknotes! The notes were first digitized, followed by a numerical transformation using DSP techniques. The final set of engineered features are all continuous in nature, meaning that our dataset consists entirely of floats, with no strings to worry about. If you're curious about how the dataset was created, you can visit the UCI link [here](https://archive.ics.uci.edu/ml/datasets/banknote+authentication)!\n", "\n", "We have following attributes in the dataset:  \n", "\n", "1. __Variance__ of wavelet transformed image (continuous) \n", "2. __Skewness__ of wavelet transformed image (continuous) \n", "3. __Curtosis__ of wavelet transformed image (continuous) \n", "4. __Entropy__ of image (continuous) \n", "5. __Class__ (integer) - Target/Label "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Import the necessary libraries \n", "\n", "We've imported all the necessary modules you will require for this lab, go ahead and run the following cell: "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#\u00a0Import necessary libraries\n", "import numpy as np \n", "import pandas as pd \n", "from sklearn.model_selection import train_test_split\n", "from sklearn.tree import DecisionTreeClassifier \n", "from sklearn.metrics import accuracy_score, roc_curve, auc\n", "from sklearn.tree import export_graphviz\n", "from IPython.display import Image  \n", "from pydotplus import graph_from_dot_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Import data\n", "\n", "Now, you'll load our dataset in a DataFrame, perform some basic EDA, and get a general feel for the data you'll be working with.\n", "\n", "- Import the file `'data_banknote_authentication.csv'` as a pandas DataFrame. Note that there is no header information in this dataset \n", "- Assign column names `'Variance'`, `'Skewness'`, `'Curtosis'`, `'Entropy'`, and `'Class'` to dataset in the given order \n", "- View the basic statistics and shape of dataset \n", "- Check for frequency of positive and negative examples in the target variable"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#\u00a0Create Dataframe\n", "\n", "## Your code here \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Describe the dataset\n", "\n", "## Your code here \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Shape of dataset\n", "\n", "## Your code here \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#\u00a0Class frequency of target variable \n", "\n", "## Your code here \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Create features, labels, training, and test data\n", "\n", "Now we need to create our feature set `X` and labels `y`:  \n", "- Create `X` and `y` by selecting the appropriate columns from the dataset\n", "- Create a 80/20 split on the dataset for training/test. Use `random_state=10` for reproducibility"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#\u00a0Create features and labels\n", "\n", "## Your code here \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Perform an 80/20 split\n", "\n", "## Your code here \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Train the classifier and make predictions\n", "- Create an instance of decision tree classifier with `random_state=10` for reproducibility\n", "- Fit the training data to the model \n", "- Use the trained model to make predictions with test data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train a DT classifier\n", "\n", "## Your code here\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Make predictions for test data\n", "\n", "## Your code here \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Check predictive performance\n", "\n", "Use different evaluation measures to check the predictive performance of the classifier: \n", "- Check the accuracy, AUC, and create a confusion matrix \n", "- Interpret the results "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate accuracy \n", "acc = None\n", "print('Accuracy is :{0}'.format(acc))\n", "\n", "# Check the AUC for predictions\n", "false_positive_rate, true_positive_rate, thresholds = None\n", "roc_auc = None\n", "print('\\nAUC is :{0}'.format(round(roc_auc, 2)))\n", "\n", "# Create and print a confusion matrix \n", "print('\\nConfusion Matrix')\n", "print('----------------')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Level up (Optional)\n", "\n", "\n", "### Re-grow the tree using entropy "]}, {"cell_type": "markdown", "metadata": {}, "source": ["The default impurity criterion in scikit-learn is the Gini impurity. We can change it to entropy by passing in `criterion='entropy'` argument to the classifier in the training phase.  \n", "\n", "- Create an instance of decision tree classifier with `random_state=10` for reproducibility. Make sure you use entropy to calculate impurity \n", "- Fit this classifier to training data \n", "- Run the given code to plot the decision tree"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Instantiate and fit a DecisionTreeClassifier\n", "classifier_2 = None\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create DOT data\n", "dot_data = export_graphviz(classifier_2, out_file=None, \n", "                           feature_names=X_train.columns,  \n", "                           class_names=np.unique(y).astype('str'), \n", "                           filled=True, rounded=True, special_characters=True)\n", "\n", "# Draw graph\n", "graph = graph_from_dot_data(dot_data)  \n", "\n", "# Show graph\n", "Image(graph.create_png())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- We discussed earlier that decision trees are very sensitive to outliers. Try to identify and remove/fix any possible outliers in the dataset  \n", "- Check the distributions of the data. Is there any room for normalization/scaling of data? Apply these techniques and see if it improves upon accuracy score "]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary \n", "\n", "In this lesson, we looked at growing a decision tree for banknote authentication dataset which is composed of extracted continuous features from photographic data. We looked at data acquisition, training, prediction, and evaluation. We also looked at growing trees using entropy vs. gini impurity criteria. In following lessons, we shall look at some more such pre-train tuning techniques for ensuring an optimal classifier for learning and prediction.  "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 2}